{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a note while I read Chapter 7 of the book \"Principles of Data Science\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we'll look at the following topics:\n",
    "- how to obtain and sample data \n",
    "- the measures of center, variance, and relative standing\n",
    "- normalization of data using the z-score \n",
    "- the Empirical rule "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are statistics \n",
    "\n",
    "**population**: entire pool of subjects of an experiment or a model \n",
    "\n",
    "We want to ask a question about the population. The question is called a **parameter**. \n",
    "\n",
    "It would be very difficult to track everyone down in order to get the answer. When this happens, it is impossible to figure out this parameter. In this case, we can **estimate** the parameter by taking a **sample** of the population. \n",
    "\n",
    "We can define a sample of a population as a subset of the population. \n",
    "\n",
    "Example, we perhaps ask 200 of the 1000 employees you have. Of these 200, suppose 26 use drugs, making the drug use rate 13%. Here, 13% is not a parameter because we didn't get a chance to ask everyone. This 13% is an estimate of a parameter. The estimate of a parameter is called a **statistic**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we obtain and sample data? \n",
    "## Obtaining data \n",
    "\n",
    "There are 2 main ways of collecting data for our analysis: observational and experimentation. \n",
    "\n",
    "### Observational \n",
    "We might obtain data through observational menas, which consists of measuring specific characteristics but not attempting to modify the subjects being studied.\n",
    "\n",
    "All you have to do is observe and collect data. \n",
    "\n",
    "### Experimental \n",
    "An experiment consists of a treatment and the observation of its effect on the subjects. \n",
    "\n",
    "They will put people into 2 or more groups(usually just two) and call them the control and the experimental group. \n",
    "\n",
    "The control group is exposed to a certain environment and then observed. The experimental group is then exposed to a different environment and then observed. \n",
    "\n",
    "The experimenter then aggregates data from both the groups and makes a decision about which environment was more favorable(favorable is a quality that the experimenter gets to decide). \n",
    "\n",
    "This, specifically, is called an A/B test. \n",
    "\n",
    "## Sampling data \n",
    "### Probability sampling\n",
    "is a way of  sampling from a population, in which every person has a known probability of being chosen but that number might be a different probability than another user. The simplest(and probably the most common) probability sampling method is random sampling. \n",
    "#### Random sampling\n",
    "A **sample bias** occurs when the way the sample is obtained systemically favors some outcome over the target outcome. \n",
    "\n",
    "A **confounding factor** (混淆因素) is a variable that we are not directly measuring but connects the variables that are being measured. \n",
    "#### Unequal probability sampling \n",
    "A probability sampling might have different probabilities for different potential sample members. \n",
    "\n",
    "A simple random sample, where everyone has the same chance as everyone else, is very likely to drown out the voices and opinions of minority population members. Therefore, it can be okay to introduce such a favoring system in your sampling techniques. \n",
    "\n",
    "Example. Suppose a company has 75% men and 25% women. This means that if we introduce a random sample, our sample will likely have a similar split and, thus, favor the results for men not women. To combat this, we can favor including more women than men in our survey in order to make the split of our samples less favored for men. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we measure statistics? \n",
    "## Measures of center \n",
    "\n",
    "The **arighetic mean** of a dataset is found by adding up all of the values and then dividing it by the number of data values. \n",
    "\n",
    "The **median** is the number found in the middle of the dataset when it is sorted in order. Median is less sensitive to outliers. When working with datasets with many outliers, it is sometimes more useful to use the median of the dataset. \n",
    "\n",
    "## Measures of variation \n",
    "Measuring how \"spread out\" the data are. \n",
    "\n",
    "The **range** is simply the maximum value minus the minimum value. \n",
    "\n",
    "Standard deviation: \n",
    "$$\n",
    "s = \\sqrt{\\frac{\\sum{(x-\\overline{x}})^2}{n}}\n",
    "$$\n",
    "\n",
    "- s is our sample standard deviation \n",
    "- x is each individual data point \n",
    "- $\\overline{x}$ is the mean of the data \n",
    "- n is the number of data points \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coefficient of variation\n",
    "is defined as the ratio of the data's standard deviation to its mean. \n",
    "\n",
    "The ratio is a way to standardize the standard deviation, which makes it easier to compare across datasets. We use this measure frequently when attempting to compare means, and it spreads across populations that exist at different scales. \n",
    "\n",
    "## Measures of relative standing \n",
    "\n",
    "The **z-score** is a way of telling us how far away a single data value is from the mean. \n",
    "\n",
    "$$\n",
    "z = \\frac{x-\\overline{x}}{s}\n",
    "$$\n",
    "\n",
    "- x is the data point \n",
    "- $\\overline{x}$ is the mean \n",
    "- s is the standard deviation\n",
    "\n",
    "## correlations in data \n",
    "**Correlation coefficients** are a quantitative measure that describe the strength of association/relationship between 2 variables. \n",
    "\n",
    "- It will lie between -1 and 1 \n",
    "- The greater the absolute value(closer to -1 to 1), the stronger the relationship between the variables \n",
    "- A positive correlation means that as one variable increases, the other one tends to increase as well \n",
    "- A negative correlation means that as one variable increases, the other one tends to decrease\n",
    "\n",
    "Note: Causation is not implied by correlation. \n",
    "\n",
    "In Julia, the **cor** function is able to calculate correlation coefficients of two vectors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.606516798326819"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srand(1) \n",
    "x=collect(1.1:0.1:2.0)\n",
    "y = [rand() for i in 1:10 ]\n",
    "cor(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the Empirical rule \n",
    "Normal distribution is defined as having a specific probability distribution that resembles a bell curve. In statistics, we love it when our data behaves *normally*. The *Empirical rule* states that we can expect a certain amount of data to live between sets of standard deviations. Specifically, the Empirical rule states for data that is distributed normally: \n",
    "- about 68% of the data fall within 1 standard deviation \n",
    "- about 95% of the data fall within 2 standard deviations \n",
    "- about 99.7% of the data fall within 3 standard deviations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
