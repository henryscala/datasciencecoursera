{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a note while I read Chapter 6 of the book \"Principles of Data Science\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter will focus on some of the more advanced topics in probability theory, including the following topics:\n",
    "- exhaustive events \n",
    "- bayes theorem \n",
    "- basic prediction rules \n",
    "- random variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collectively exhaustive events\n",
    "When given a set of two or more events, if at least one of the events must occur, then such a set of events is said to be collectively exhaustive. \n",
    "\n",
    "Side note: There is a socalled MECE principle. Mutually Exclusive, Collectively Exhaustive. The principle is often used when writing an article to describe sth. \n",
    "\n",
    "Example: \n",
    "- Given a set of events ${temperature < 60, temperature > 90}$. It is not collectively exhaustive, because there is ${60 <= temperature <= 90}$. However, they are mutually exhaustive because both cannot happen at the same time. \n",
    "- In a dice roll, the set of events of rolling ${1, 2, 3, 4, 5, 6}$ are collectively exhaustive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian ideas revisited\n",
    "When speaking about Bayes, you are speaking about the following 3 things and how they all interact with each other: \n",
    "- A prior distribution \n",
    "- A posterior distribution \n",
    "- A likelihood\n",
    "\n",
    "Basically, we are concerned with finding the posterior. That's the thing we want to know. \n",
    "\n",
    "Another way to phrase the Bayesian way of thinking is that data shapes and updates our belief. We have a prior probability, or what we naively think about a hypothesis, and then we have a posterior probability, which is what we think about a hypothesis, given some data. \n",
    "\n",
    "## Bayes theorem \n",
    " \n",
    "$$\n",
    "P(A|B)=\\frac{P(A)*P(B|A)}{P(B)}\n",
    "$$\n",
    "\n",
    "The theorem is concluded from the fact that $P(B)*P(A|B) = P(A)*P(B|A)$. \n",
    "\n",
    "You can think of Bayes theorem as follows: \n",
    "- It is a way to get from P(B|A) to P(A|B) (if you only have one) \n",
    "- It is a way to get P(A|B) if you already know P(A) (without knowing B)\n",
    "\n",
    "Let's try thinking about Bayes using the terms hypothesis and data. Suppose H = your hypothesis about the given data, and D = the data that you are given. \n",
    "\n",
    "Bayes can be interpreted as trying to figure out P(H|D) ( The probability that our hypothesis is correct, given the data at hand). \n",
    "\n",
    "$$\n",
    "P(H|D)=\\frac{P(H)*P(D|H)}{P(D)}\n",
    "$$\n",
    "\n",
    "- P(H) is the probability of the hypothesis before we observe the data, called the prior probability or just prior. \n",
    "- P(H|D) is what we want to compute, the probability of the hypothesis after we oberve the data, called the posterior. \n",
    "- P(D|H) is the probability of the data under the given hypothesis, called the likelihood. \n",
    "- P(D) is the probability of the data under any hypothesis, called the normalizing contant. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example \n",
    "Consider that you have two people in charge of writing blog posts for your company - Lucy and Avinash. From past performances, you have liked 80% of Lucy's work and only 50% of Avinash's work. A new blog post comes to your desk in the morning, but the author isn't mentioned. You love the article. What is the probability that it came from Avinash? Each blogger blogs at a very similar rate. \n",
    "\n",
    "- H=hypothesis=the blog came from Avinash \n",
    "- D=data=you loved the blog post \n",
    "\n",
    "- P(H|D) is what we want to compute. It means the probability that it comes from Avinash, given that I loved it. \n",
    "- P(H) is the probability that an article come from Avinash. \n",
    "- P(D) is the probability that I love an article. \n",
    "- P(D|H) is the probability that I loved it, given that it came from Avinash. \n",
    "\n",
    "P(D|H) is 0.5. \n",
    "\n",
    "P(H) is 0.5. \n",
    "\n",
    "$P(D) = P(H)P(D|H) + P(\\overline{H})P(D|\\overline{H}) = 0.5 * 0.5 + 0.5 * 0.8$ \n",
    "\n",
    "P(H|D) is 0.38 based on above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random variables \n",
    "A random variable uses real numerical values to describe a probabilisic event. \n",
    "\n",
    "In math and programming, we were used to the fact that a variable takes on a certain value. In a random variable, we are subject to randomness, which means that our variables' values are, well just that, variable. They might take on multiple values depending on the environment. \n",
    "\n",
    "We generally use single capital letters(mostly the specific letter X) to denote random variables. For example, we might have: \n",
    "- X = the outcome of a dice roll \n",
    "- Y = the revenue earned by a company this year \n",
    "- Z = the score of an applicant on an interview coding quiz(0-100%) \n",
    "\n",
    "Effectively, a random variable is a function that maps values from the sample space of an event(the set of all possible outcomes) to a probability value(between 0 and 1). Think about the event as being expressed as the following: \n",
    "\n",
    "$$\n",
    "f(event) = probability \n",
    "$$\n",
    "\n",
    "There are 2 main types of random variables: discrete and continuous. \n",
    "\n",
    "## Discrete random variables \n",
    "A discrete random variable only takes on a countable number of possible values. For example, the outcome of a dice roll, as shown here: \n",
    "\n",
    "X = the outcome of a single dice roll \n",
    "\n",
    "<table>\n",
    "<tr><td>Value</td><td>X = 1</td><td>X = 2</td><td>X = 3</td><td>X = 4</td><td>X = 5</td><td>X = 6</td></tr>\n",
    "<tr><td>Probability</td><td>1/6</td><td>1/6</td><td>1/6</td><td>1/6</td><td>1/6</td><td>1/6</td></tr>\n",
    "</table>\n",
    "\n",
    "We'll use a probability mass function(PMF) to describe a discrete random variable. \n",
    "\n",
    "P(X = x) = PMF. \n",
    "\n",
    "So, for a dice roll, P(X=1)=1/6, and P(X=5)=1/6. \n",
    "\n",
    "Random variables have many properties, two of which are their *expected value* and the *variance*. \n",
    "\n",
    "For a discrete random variable, we can also use a simple formula, shown as follows, to calculate the expected value: \n",
    "\n",
    "$$\n",
    "Expected\\ value = E[X] = \\mu_x = \\sum{x_i p_i}\n",
    "$$\n",
    "\n",
    "The formula for the variance of a discrete random variable is expressed as follows: \n",
    "\n",
    "$$\n",
    "Variance = V[X] = \\sigma_x^2=\\sum{(x_i - \\mu_x)^2 p_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## types of discrete random variables \n",
    "### binomial random variables \n",
    "A binomial setting has the following 4 conditions:\n",
    "- The possible outcomes are either success or failure \n",
    "- The outcomes of trials cannot affect the outcome of another trial \n",
    "- The number of trials was set(a fixed sample size) \n",
    "- The chance of success of each trial must always be p. \n",
    "\n",
    "A binomial random variable is a discrete random variable, X, that counts the number of successes in a binomial setting. The parameters are n = the number of trials and p = the chance of success of each trial. \n",
    "\n",
    "The PMF for a binomial random variable is as follows: \n",
    "\n",
    "$$\n",
    "P(X=k) = \\left\\lgroup \\matrix{n\\\\k} \\right\\rgroup p^k(1-p)^{n-k}\n",
    "$$\n",
    "\n",
    "Here, $\\left\\lgroup \\matrix{n\\\\k} \\right\\rgroup = the\\ binomial\\ coefficient = \\frac{n!}{(n-k)!k!}$\n",
    "\n",
    "Shortcuts to binomial expected value and variance. \n",
    "\n",
    "$$\n",
    "E(X) = np \\\\\n",
    "V(X) = np(1-p)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric random variable \n",
    "It is actually quite similar to the binomial random variable in that we are concerned with a setting in which a single event is occurring over and over. However, in the case of a geometric setting, the major difference is that we are not fixing the sample size. \n",
    "\n",
    "Specifically, a geometric setting has the following four conditions: \n",
    "- The possible outcomes are either success or failure \n",
    "- The outcomes of trials cannot affect the outcome of another trial \n",
    "- The number of trials was not set \n",
    "- The chance of success of each trial must always be p. \n",
    "\n",
    "Note that these are the exact same conditions as a binomial variable, except the 3rd condition. \n",
    "\n",
    "A geometric random variable is a discrete random variable, X, that counts the number of trials needed to obtain one success. The parameters are p = the chance of success of each trial, and (1-p) = the chance of failure of each trial. \n",
    "\n",
    "The formula for the PMF is as follows: \n",
    "$$\n",
    "P(X=x) = (1-p)^{x-1}p\n",
    "$$\n",
    "\n",
    "Example - wheather \n",
    "\n",
    "There is a 34% chance that it will rain on any day in April. Find the probability that the first day of rain in April will occur on April 4. It means from April 1 to 3, there is no rain. And on April 4, there is rain. \n",
    "\n",
    "$$\n",
    "P(4) = 0.66^3 * 0.34 = 0.63 \n",
    "$$\n",
    "\n",
    "Shortcuts to geometric expected value and variance. \n",
    "\n",
    "E(X)=1/p \n",
    "\n",
    "V(X)=(1-p)/p2 ( it is ambiguous, need to figure out in future whether the 2 belongs to numerator or denominator ) \n",
    "\n",
    "### Poisson random variable \n",
    "To understand why we would need this random variable, imagine that an event that we wish to model has a small probability of happening and that we wish to count the number of times that the event occurs in a cerain time frame. If we have an idea of the average number of occurrences, $\\mu$, over a specific period of time, given from past instances, then the Poisson random variable, denoted by $X=Poi(\\mu)$, counts the total number of occurrences of the event during that given time period. \n",
    "\n",
    "In other words, the Poisson distribution is a discrete probability distribution that counts the number of events that occur in a given interval of time. \n",
    "\n",
    "If we let $X = \\text{the number of events in a given interval}$, and the average number of events per interval is the $\\lambda$ number, then the probability of observing x events in a given interval is given by the following formula: \n",
    "\n",
    "$$\n",
    "P(X=x)=\\frac{e^{-\\lambda}\\lambda^x}{x!}\n",
    "$$\n",
    "\n",
    "Here, e = Euler's constant\n",
    "\n",
    "Example - call center \n",
    "\n",
    "The number of calls arriving at your call center follows a Poisson distribution at the rate of 5 calls/hour. What is the probability that exactly 6 calls will come in between 10 and 11 p.m.? \n",
    "\n",
    "$$\n",
    "P(X=6) = \\frac{e^{-\\lambda}\\lambda^x}{x!} = \\frac{e^{-5}5^6}{6!} = 0.146 \n",
    "$$\n",
    "\n",
    "Shortcuts to Poisson expected value and variance \n",
    "\n",
    "$$\n",
    "E(X) = \\lambda \\\\\n",
    "V(X) = \\lambda \n",
    "$$\n",
    "\n",
    "## continuous random variables \n",
    "A continuous random variable can take on an infinite number of possible values, not just a few countable ones. We use PDF instead of PMF to describe the functions.\n",
    "\n",
    "If X is a continuous random variable, then there is a function, f(x), such that for any constans a and b: \n",
    "$$\n",
    "P(a \\le X \\le) = \\int\\limits_a^bf(x)dx\n",
    "$$\n",
    "\n",
    "The preceding f(x) function is known as the PDF(probability density function). \n",
    "\n",
    "The most important continuous distribution is the standard normal distribution. The PDF of this distribution is as follows: \n",
    "\n",
    "$$\n",
    "f(x)=\\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n",
    "$$\n",
    "\n",
    "Here, $\\mu$ is the mean of the variable and $\\sigma$ is the standard deviation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
